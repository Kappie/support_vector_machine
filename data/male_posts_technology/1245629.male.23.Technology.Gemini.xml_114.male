


       
      Bill Joy again, a great man living admist us.He says us to Proceed with caution.        urlLink nytimes article . Bill Joy finished his 21-year career at Sun Microsystems, the huge technology company he helped create and build, early last September. At that time, Sun sent out a press release to announce that its chief scientist was leaving and had no definite plans. This was true: Joy had only vague notions of what he would do next.  As he departed, he told a reporter he wanted to sit down and relax with a glass of wine and a blank sheet of paper. This was perhaps not so true: it's hard to imagine Joy with a blank sheet of paper. Thoughts and ideas pile up furiously in his notebooks; diagrams and scribbles and equations issue forth at all hours of the day and night.  When Joy, 49, finally moved out of a small Sun office in downtown Aspen, where he had worked since the late 1980's, he had to archive 900 pounds of professional papers. Then it took him months to go through his personal records, which filled 20 fireproof file cabinets.   Over the past few months, Joy has been splitting his time between a new house in Marin County, Calif., and his main home in Aspen, where his two children go to school. ''I'm in an in-between thing,'' he says. Indeed, there are at least two Bill Joys. Start with Joy the computer scientist -- or computer architect, as he often describes himself -- a Silicon Valley deity, generally regarded as one of the most gifted engineers ever to have negotiated freeway traffic. Much of the present-day Internet is built upon the Unix code Joy wrote in the 1970's when he was a grad student at Berkeley; after that, his signature inventions shaped the Java programming language and the Sun computer servers that power a good portion of the Web. This Bill Joy recently flirted with the idea of taking a job at Google and continues to entertain pitches from friends and strangers eager to have him join their start-ups. The challenge is to find the right one.  As Joy says, he wants to do something in technology again, but only something new, something different, ''something that isn't going to happen anyway'' without his help.   The other Bill Joy, however, would very much like to prevent the inevitable from happening. Four years ago in an article he wrote for Wired magazine, Joy declared that the headlong race in biotechnology and nanotechnology might prove catastrophic. In the time since, he has continued to explore and advance this concern. Joy says he thinks the probability of a ''civilization-changing event'' is most likely in the double digits, perhaps as high as 50 percent. He doesn't merely ascribe these odds to terrorism; he suggests a pandemic disease might arise from a sudden accident or as a consequence of cutting-edge research. For disquieting evidence, he points out that a couple of years ago scientists assembled polio in a lab. That in late 2002 J. Craig Venter, the founder of Celera Genomics, announced plans to create organisms from scratch. That only a few months ago scientists were tinkering with deadly strains of bird flu in less-than-top-security labs.  That the genomic sequence for the plague is now on the Web for anyone to see or make use of.    Joy calls the bird-flu experimentation ''insane.'' But he is fixated less on whether scientists committed ethical breaches in this case than on whether the larger scientific community can temper the pace of innovation before it's too late. He's not exactly optimistic, predicting that public awareness will most likely come only after an actual accident at a company or a university. Until then, he says, speed -- the mad rush for patents and market share and money -- will trump caution. Regulatory agencies are structured to catch shady C.F.O.'s, not reckless private-sector technologists. And markets are ill equipped to play traffic cop. ''Markets are extremely good at go,'' Joy says. ''They're not very good at stop. And I think we need a little bit of stop right now. Or else we're not going to like the outcome.''    One of Joy's favorite coffee shops in Aspen is Zele, a bustling downtown hangout where he has been a regular for half a decade. On a sunny morning in March, I waited at a window seat and watched him arrive from half a block away. There was no mistaking him. Lanky and loose-limbed and well over six feet, Joy wore faded sweat pants and an old sweatshirt; his hair, always tousled in photographs, actually stood vertically on end.  Joy seemed so utterly lost in concentration as he crossed the street that for a moment I worried he might be hit by a passing car.  Then he tuned in, came inside and introduced himself with a big grin and a handshake. He took off his watch, unplugged his headphones, unstrapped an iPod mini from his upper arm and dumped the gadgetry, along with a Treo already chiming with incoming e-mail, on the table.   Over the past few years, Joy has often been characterized in the press and on the Web as haunted by grim possible futures and tortured by whatever role he might have played in leading us to them. In person he comes across as a serene technology enthusiast, working through his talking points without anxiety or heat. Unlike Bill McKibben or Wendell Berry, two authors Joy admires who have written with passion about how technology threatens to devalue our day-to-day lives,  Joy has made a point of not pursuing the moral, religious or political dimensions of his argument. ''I'm focused on truly catastrophic danger, where we must act,''  he wrote to me in a late-night e-mail message.   Joy began writing a book about his concerns several years ago. The result was a 50,000-word manuscript, written between projects at Sun and never published, that he said he hoped would awaken a lay public to the potential dangers of genetic engineering, robotics and nanotechnology. In September 2001, Joy took the manuscript with him to New York, where he rented two adjoining rooms -- one for writing and one for sleeping -- in the Mercer Hotel in SoHo. On the night of Sept. 10, he stayed up past 4 a.m. sorting hundreds of books on terrorism, flu epidemics, plagues and bioweapons. He had just shipped them in from Aspen. Joy says: ''I woke up four hours later to smoke and sirens, with this manuscript about using technology to do terrorism right next to me. Spooky.''   He scrapped the idea of a book as a wake-up call. He began an ill-fated second draft with a sociological theme (cultural responses to death) and then tried a third draft, relating scientific research to capital markets and the law. Joy is adamant that modern technology has wreaked a huge imbalance of power. A lethal virus fashioned in a lab or a genetic experiment gone awry is far worse than the dynamite that Alfred Nobel invented nearly 140 years ago, because the self-replicating nature of these dangers leaves an inordinate amount of responsibility in the hands of a single scientist or corporation. In Joy's view, the legal system is now powerless to stop a rogue scientist or a negligent technologist.   He is likewise sure that the financial markets do not acknowledge the true hazards of certain kinds of science. To Joy this is a hugely important point.  He isn't keen on regulation, since he considers it far less effective than market forces.  (A millionaire many times over from his shares in Sun and other tech start-ups, Joy knows the fruits of the market firsthand.) Yet he does think we now need to ''manage'' the system somewhat. He says he believes that businesses doing research in areas deemed risky by their peers should be forced to take out insurance against catastrophes. He also says that science guilds should have the authority to limit access to potentially dangerous ideas. ''Perhaps some knowledge won't be made public,'' Joy says. ''Perhaps there would be secrets. You know, you couldn't just get the code to the plague or the flu if you wanted it.'' In this model, any given firm could be refused genomic information by a guild, or bankrupted by insurance costs, or rejected by venture capitalists or investors frightened away by potential expenses and liabilities.   These notions made it into his book's final draft. But that draft will never be published. ''The book got away from me,'' Joy says. He wasn't satisfied he had come up with a comprehensive set of solutions, and by mutual agreement with his publisher he pulled the plug. He finished paying back a six-figure contract advance a few months ago. I asked if it was harder to write software systems than to write a book. ''With code, the computer tells you if it understands what you write,'' he says. ''It's much harder to write prose. That is, if you want to be understood.''    If there is a key to understanding Joy's point of view, a code to his code, it is recognizing his preoccupation with risk instead of fear. Making us think about potential ''bad outcomes'' is his goal; scaring the hell out of us is not. Joy often uses the free market as an example of a system where any outcome, good or bad, is possible. At the moment, he argues, the same potential for good and bad outcomes exists in various kinds of private-sector research. The problem, though, is that a single bad biotech outcome may quickly become epidemic, unstoppable and irreversible. ''Markets can take us places we don't want to go,'' he says, ''and science, unchallenged and uninhibited, will take us places we don't want to go.'' As a contrast, Joy brings up the example of the operating systems he writes so well, where information is carefully architected and vast numbers of computational outcomes are anticipated. Even the freakish occurrence, the wildest mistake, is taken into account.   The theme of risk runs through Joy's other work. He characterizes his efforts at Berkeley and Sun as a 25-year project to make computing simpler, more reliable and more secure. A longtime foe of Microsoft, he is particularly scathing when it comes to the bugs and vulnerabilities of that software company's operating system. Windows creates risk; Windows tempts a bad outcome. It's a logic Joy applies to his personal life as well. At his house in Aspen one afternoon, Joy went downstairs to help his 8-year-old daughter choose a movie to watch. Joy is a film buff, and he recently outfitted his basement with a spectacular home entertainment system. He also happens to be a bibliophile, so he bought three handbooks -- ''Halliwell's Film Guide,'' Pauline Kael's ''5001 Nights at the Movies'' and the ''Time Out Film Guide'' -- to compare reviews. ''I was going through the books and found out there are only about 2,000 movies in history in which there's critical consensus that they're really good,'' he told me. ''So I bought 600 of them.'' No bad movies, fewer possible bad outcomes.   Of course, genetic engineering isn't ''Seven Brides for Seven Brothers,'' which Joy urged upon his daughter. But his focus on consequences stays constant. Nanotechnology and biotech are supposed to save lives and brighten the future; Joy isn't sure we can bank on that. We should instead question the bedrock assumption that good science equals beneficial science. Good science, he says, is the discovery of truth -- for example, an experiment that yields an accurate result and that is repeatable. But science may not be good for us anymore if it yields a bad outcome. ''The Greeks knew better,'' Joy says. ''Oedipus was destroyed by truth. He looked like he had a happy life until he learned one too many things. That's the cautionary tale.''   A few years ago, a friend gave Joy a paperback copy of the autobiography of Bertrand Russell. Russell began his career in mathematics, like Joy, before switching to what would become his better known work in logic and philosophy. Like Joy, Russell spent much of his later career agitating for change and speaking out against the perils of technology -- in that era, nuclear weapons. When Joy brought up Russell's book in conversation with me, he found a copy in his living room and began reading in a pleasant monotone:  ''I thought that people would not like the prospect of being fried with their families and their neighbors and every living person that they had heard of. I thought it would only be necessary to make the danger known and that, when this had been done, men of all parties would unite to restore previous safety. I found that this was a mistake. There is a motive which is stronger than self-preservation: it is the desire to get the better of the other fellow.''  When he finished reading, Joy closed the book and said, ''I understand exactly where he's coming from.''   Indeed, while Joy defines himself as a realist, never as a pessimist, he sometimes betrays a frustration akin to Russell's. He is encouraged, for instance, that weapons of mass destruction have become water-cooler talk and that his speeches and writings have sparked a certain amount of debate in the scientific community. (Joy has been especially provocative on the threat of tiny self-replicating ''nanobots'' reducing all earthly matter -- us included -- to dust. This is what's known among theoreticians as the ''gray goo'' problem.) On the other hand, there have been scientists in the public and private sectors who have characterized Joy as a neo-Luddite. Or who regard him as an outlier, a software writer unqualified to speak authoritatively about the complexities of biotechnology.   Joy admits such insults and marginalization have been difficult. Still, he claims to be more daunted by the complacency of human nature. ''It's hard for people to accept that something will happen if it hasn't happened yet,'' he says. In recent months, he's come to the conclusion that getting further involved in public policy might be the most sensible next step. Joy served on a technology commission during the Clinton presidency and has ties to a number of politicians in Washington. He doesn't consider the Bush administration receptive to his ideas on market restraint, and in the event of its re-election, he would try a fourth time to write a book. In the event of a Kerry administration, he says, he would work his contacts and go to D.C. More than anything, he wants to start a public debate. ''You only get one shot with this kind of thing,'' Joy told me.   And yet when scientists issue their warnings in some far-off corner of Congress, does anybody hear them? I asked Joy about this in various ways over the past few months. When I wrote him one morning to say that the fact that we couldn't yet cure baldness suggests that the risks he describes are far, far away, he wrote back around midnight, sending me a link to some research that suggests baldness might soon be cured. Then he added that regrettably it is easier to destroy than to create, and nature provides a ready-made toolbox of pathogens to adapt from. The issue is how widespread and easy we are going to make the ability for individuals to do this. That we can accidentally create fatal new pathogens is not a theoretical possibility but a practical actuality.   In an earlier conversation, Joy had singled out James Watson, who discovered with Francis Crick the double helix of DNA, as a scientist who rejects Joy's arguments for weighing benefits against bad outcomes. Watson has indeed said that it makes little sense to stop research on account of unspecified risks or ''evil.'' In the name of science and discovery, he says, we are ethically obliged to go forward. ''That position has to be wrong,'' Joy insists. In his view, we are ethically bound to slow down.   This is not an easy case to make. In his last unpublished manuscript, speaking of those in the science and business communities who dispute the catastrophic potential of their work, Joy said, ''I wonder where these people hide their fear.'' I asked Joy about this in another e-mail message. Where is the fear today? A few days after, at 2:10 a.m., Joy wrote: ''I think our lack of pandemic experience is the key. We don't know what it feels like. It seems like Hollywood. It isn't real enough to us that we demand action, we just file the catastrophic thought and tolerate its dissonance and that it conflicts with other things we believe. As humans we do this so well. And, of course, there is Bertrand Russell's experience. . . . But I hope that we can transcend his bitter experience, somehow, now. We must try.''   Some weeks later, he sent a note to point out that a SARS research lab in China had been shut down that day. A safety breach had led to several infections. ''This is the reality of handling such dangerous things,'' he wrote.  He had wanted to remind me. Accidents will happen.    Jon Gertner is a contributing writer for the magazine. 
     

    
