


       
      Monkeys that can move a robot arm with thoughts alone have brought the merger of mind and machine one step closer.  In experiments at Duke University, implants in the monkeys' brains picked up brain signals and sent them to a robotic arm, which carried out reaching and grasping movements on a computer screen driven only by the monkeys' thoughts.  The achievement is a significant advance in the continuing effort to devise thought-controlled machines that could be a great benefit for people who are paralyzed, or have lost control over their physical movements.  In previous experiments, some in the same laboratory at Duke, both humans and monkeys have had their brains wired so they could move cursors on computer screens just by thinking about it. And wired monkeys have moved robot arms by making a motion with their own arms. The new research, however, involves thought-controlled robotic action that does not depend on physical movement by the monkey and that involves the complex muscular activities of reaching and grasping.  The study is being published today in the inaugural issue of The Public Library of Science, a peer-reviewed scientific journal that makes articles available free of charge. The research team was led by Dr. Miguel A. L. Nicolelis, a neurobiology professor and co-director of the Center for Neuroengineering at Duke, in North Carolina. Dr. Nicolelis also did the earlier research on monkeys and robot arms at Duke.  While other laboratories have helped monkeys use thoughts to move robots, using different experimental designs, the Duke findings go furthest in the sense that their robots were mentally assimilated into the animals' brains.  "For nearly completely paralyzed people, this promises to be a fantastic boon," said Dr. Jon Kaas, a psychology professor at Vanderbilt University in Nashville, who is familiar with Dr. Nicolelis's research. "A person could control a computer or robot to do anything in real time, as fast as they can think."  While experts agree that thought-controlled personal robots are many years off, the Duke University team recently showed that humans produce brain signals like those of the experimental monkeys.   "Monkeys not only use their brain activity to control a robot," said Dr. John Chapin, a professor of physiology and pharmacology at the State University of New York Downstate Medical Center in Brooklyn. "They improve their performance with time. The stunning thing is that we can now see how this occurs, how neurons change their tuning as the monkey does different tasks."  Dr. Nicolelis implanted tiny probes called microwires into several brain regions of two rhesus monkeys. At first, each monkey learned to move a joystick that controlled a cursor on a computer screen. When a ball appeared, the animal had to move the cursor to the target to earn a drink of juice. Researchers collected electrical patterns from the monkey's brain as it performed the tasks.  After the monkey became skilled at the exercise, the scientists disconnected the joystick. At first, the monkey jiggled the stick and stared at the screen, Dr. Nicolelis said. Even though the joystick was not working, the monkey's reaching and grasping motor plans were being sent to a computer, which translated those signals into movements on screen.  There was an "incredible moment" when the monkey realized that it could guide the cursor and grasp an object on the screen just by thinking it, Dr. Nicolelis said. The arm dropped. Muscles no longer contracted.  The final step was to divert brain signals to a computer model that controlled the movements of a robot. The monkey continued to think the movements but in doing so it now moved the robot arm directly, without a joystick, which in turn directed movements of the cursor.  Controlling a shaky, jerky robot with thought is not easy, Dr. Nicolelis said. When the robot is first added, the monkey's performance degrades. It takes two days for the animal to learn the mechanical properties of the arm and to incorporate its delays into motor planning areas.  "By the end of training, I would say that these monkeys sensed they were reaching and grasping with their own arms instead of the robot arm," Dr. Nicolelis said. "Every time we use a tool to interact with our environment, such as a computer mouse, car or glasses, our brain assimilates properties of the tool into neuronal space. Tools are appendages which are incorporated into our body schema. As we develop new tools, we reshape our brains," he said. 
     

    
