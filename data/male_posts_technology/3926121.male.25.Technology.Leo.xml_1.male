

	 
      I just ran across a Java Benchmarking Framework called  urlLink JBench . I was quite interested since I haven't tried any official benchmarking, so I downloaded and reviewed it. It's not a stand-alone benchmarking tool like a CPU or graphics card benchmarker. It is a framework similar to JUnit that requires the programmer to put some thought into what they are testing and actually write some code. Without further ado, here's my review along with some generic benchmark testing notes.        BENCHMARK TESTS    ---------------------------     Purpose of Benchmark Tests   The purpose of benchmark tests is to determine how a certain implementation performs. Benchmark tests are commonly used to compare different algorithms, data structures, implementation, etc. against each other. Another benefit of benchmark tests is to prove that your implementation is correct for the situation. It can be used in documentation and to answer future "Why did you do it that way?" questions.    Benchmarks are not functional tests. While they might test some functionality, their main purpose is not to verify the functional correctness of the code.    Benchmarks are not load or stress tests. While they put load and stress on the code, their main purpose is to test the speed of the code and not to test how the code handles a stress-induced crash or how it effects the system resources.    Benchmarks are not performance tests. They do output performance statistics, but those statistics are not used to determine a pass/fail of the performance requirements.       Benchmark Purpose Examples   Test performance of code with logging at different levels.  Test in-house code against third-party code that does something similar.  Test a generic implementation against a specific implementation.  Test an algorithm's efficiency with different parameters, different sizes, etc.  Test the same code under different resources (JVMs, OSs, CPUs, RAM sizes, etc.)       JBench   JBench is a framework for benchmarking java code much in the same way that JUnit is a framework for unittesting java code.    To create a Benchmark test using the JBench framework, create a class that implements the uk.org.skeet.jbench.BenchTask interface. Overwrite the constructor to do one-time setups, checkConfiguration() to verify the data in the properties file, prepareTests() for setup that needs to be done before the tests are run (only called once per task, not once per jbench.runs),  runTest() to actually execute the code being benchmarked, checkResults() to do any post-test verification, and getDescription that returns a String which is printed out to describe the test being run. All variables defined for the test in the properties file should have a setVariable() method.    All the test parameters and scenarios are defined in a properties file given as a command-line option to the JBench program. Some items listed in this file is how many iterations of the runTest function is done for each test, which classes are the benchmark tests along with test variables, and information to output. The same test can be listed twice with different variables which allows it to be benchmarked in different ways.    The one concern I have is that it hasn't been developed for 3 years. There is only mention of java 1.1 and 1.2 on the website, so the behavior on 1.3 and 1.4 is unknown. Also, operating systems that have been developed in the past 3 years (Linux 2.6 kernel, Solaris 9, Windows XP) might produce unknown behavior. Judging by the small examples I have done (java 1.4 on Linux 2.6 kernel), it seems to perform correctly.    Website: http://www.yoda.arachsys.com/java/jbench/       JBench Output Analysis   Before the tests are run, data is printed out on the environment, like the JVM, OS, and JRE used. This data can be used to distinguish between tests where those parameters change. Next the data for each test is printed out. This includes a description of the test, the result of the test, and if successful, the time it took for each test iteration (specified by jbench.runs). At the bottom of each test is the mean, variance, and standard deviation.    To give a quick refresher of the terms:  - The mean of a data set is simply the arithmetic average of the values in the set, obtained by summing the values and dividing by the number of values.    - The variance of a data set is the arithmetic average of the squared differences between the values and the mean.    - The standard deviation is the square root of the variance    The mean is a measure of the center of the distribution. The variance and the standard deviation are both measures of the spread of the distribution about the mean. For benchmarking purposes, the smaller the mean the better (i.e. the faster the code executed), and the smaller the standard deviation the better. A large standard deviation indicates that the function is inconsistant, the testing platform is unstable, or other events are occuring regularly like garbage collection.       Benchmark Coding Standards (my personal preferences)   The benchmark tests should be kept in a seperate directory structure that is parallel to the source tree. No test code, including benchmark tests, should be kept in the same location or file as production code. All configuration files, libs, and all other supporting files should also be kept under this seperate and parallel directory structure.    The test class should be named the same as the class it is benchmarking, but appended with JBench (i.e. ListJBench). If the test class is only testing a function or specific functionality of that class, then it should be named approprietly (i.e. Class_functionJBench). Note that if a different framework is used for benchmarking, then a unique name for that framework should be appended instead of JBench.    Example Setup:  root/[src,conf,lib]  root/src/com/jake/commons/datastructure/ReadWriteLock.java  root/bench/lib/jbench-0.61.jar  root/bench/conf/datastructure.jbench  root/bench/src/com/jake/commons/datastructure/ReadWriteLockJBench.java  root/bench/src/com/jake/commons/datastructure/ReadWriteLock_allWritersJBench.java       JBench Example Run   LD_LIBRARY_PATH=benchmark/shlib/linux java -Xruncputimer -classpath $CLASSPATH:/home/jake/IdeaProjects/examples/target/test-classes: /home/jake/IdeaProjects/examples/target/classes: /home/jewerdt/IdeaProjects/examples/benchmark/lib/jbench-0.61.jar uk.org.skeet.jbench.JBench benchmark/conf/datastructure.jbench   
    
