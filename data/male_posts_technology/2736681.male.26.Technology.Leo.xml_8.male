

     
      Read  urlLink this  on TheServerSide, about MDA. Its an interesting article. The distinction between "elaborationist" and "translationist" MDA is a very good observation, although I don't like the words. I am firmly in the former camp, and have considerable skepticism about the scalability of the second.  Here are some responses to some comments in the article.  If the business changes as rapidly as technology, then there's no need in it being independent of its supporting technology.  Yes, very true. However, technology independence is just one benefit of "my" MDA (i.e. MDA as I understand the term). Another is an automated (or partially automated) mapping between your business concepts and your technology concepts. So, when your business model changes, your tech should change accordingly, even its still the same platform.   But for enterprise systems at least the dominance of .Net, Java and web services for the network means that the underlying technology platforms landscape looks remarkably stable for the time being.  Its all very well to talk about the portability of Java, or CORBA for that matter, but the rubber hits the road when you switch EJB providers, or ORBS, and it all falls in a heap. I can personally remember deployment descriptors being a nightmare with EJB, as recently as a couple of years ago.   It's not as if MDA removes platform risk. Consider this fragment of a generated application as produced by Compuware's OptimalJ:  Good point. This is an argument for using standard stuff. Either standardised transformation languages or, in this case, defacto standards for libraries. Also, it reinforces the frequently quoted claim that MDA isn't going to totally automate your development. It will just help. From what I've seen, EMF has a more flexible approach to this sort of problem with its generator models, and the ability to configure its generators.   Any technology that deals in meta-meta-models is going to be a hard sell, no matter how many analyst's reports have been written.  Amen. My previous employer tried to sell a MOF, and IMHO a pretty good one, for years, and just couldn't make a business of it. Admittedly, it was before its time...   Those organizations that used UML only for blueprints or sketches (Fowler's analysis [4.]) will find that MDA does not permit the use of UML in that way.  This is just plain wrong. There is no reason that they cannot keep using UML in the same way. You don't have to transform it if you don't want to.   While OCL is great for formally defining the semantics published interfaces between components, it's overkill to attempt to do this for the unpublished interfaces of objects within components. It just adds too much rigour at the wrong points in the development process, and in turn impedes agility.  Agreed. See above comments about scalability. Also, from a usability perspective, OCL is not as friendly as programming languages. Actually, its just plain not friendly.   Tool support for generic MOF capabilities, as required by a strict interpretation of the elaborationist approach, is still very patchy.  Wrong! MDR (Sun) and EMF (IBM) are both stable and pretty mature, and have two of the biggest names in IT behind them to boot. However, ...   While many UML tools allow PIMs and PSMs to be defined, they are not in themselves MOF-aware. They can be used to import/export MOF XMI format because they understand the UML namespaces, but they cannot be used for arbitrary MOF models.  Yes, this part is true, but the implication that this problem (of native syntaxes for arbitrary metamodels) should be solved in existing UML tools just scares me silly. I'm yet to meet a UML tool that I didn't swear at, and I don't like the idea of being forced to use them. Lack of automated editor generation for metamodels is a problem, but lets not heap it on UML tools.   For the OMG's view of elaborationist MDA to succeed, vendors must not only make their UML tools MOF-aware, they must also support QVT (once it is defined). Although I should be careful not to prejudge this, these are the same sort of vendors who have not implemented the OMG's earlier CWM for their various data modelling tools, a much easier proposition.  Yeah, MOF compliance would be nice, but it ain't gonna happen - there is no customer demand, and its a lot of work. For now, we'll have to settle for XMI to shunt our UML models across to MOF tools like MDR and EMF, run our transformations, then perhaps shunt the XMI back (if we're still in UML). I have the same complaint as before w.r.t. CWM - I think there will be a different market for UML than for MOF, and CWM lives in the latter. As for implementing it, I think I did, years ago. You just put the model into a MOF tool, and voila, out comes a billion lines of java code. Implemented.   More substantially, the use of metadata annotations in a PIM is remarkably similar to a couple of technologies that will become much more important, namely Java 1.5 metadata coupled with aspect-oriented programming (AOP). When AspectJ is enhanced to define pointcuts based on Java 1.5 metadata tags, these will start to act very much in the same way as PSMs.  Can someone point me to what is meant by Java 1.5 metadata, please? I assume he doesn't mean javax.jmi, because that is after all just a MOF mapping.   As for Microsoft? Noticeable by its absence.  Not really, Whitehorse, in the next version of Visual Studio, is just MDA by another name. Wisely (in my opinion), they steer away from UML 2 (see my previous post), although I'm not quite sure why they don't go the MOF way. Perhaps its just a traditional aversion to OMG? Anyway, see  urlLink Keith Short's blog  for just how MDA Microsoft is.  He also talks about Naked Objects. At a first glance, this sounds like MDA without the reflection. If this is the case, why not just use models?
     
    
